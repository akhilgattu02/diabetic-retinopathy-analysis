{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e7bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.7.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.22.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (80.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m  \u001b[33m0:00:21\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp313-cp313-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "\u001b[2K  Attempting uninstall: torch\n",
      "\u001b[2K    Found existing installation: torch 2.7.0\n",
      "\u001b[2K    Uninstalling torch-2.7.0:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.0━━\u001b[0m \u001b[32m0/2\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.22.032m0/2\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.22.0:━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.22.0\u001b[32m0/2\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchvision]\u001b[0m [torchvision]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.7.0 requires torch==2.7.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.9.1 torchvision-0.24.1\n",
      "Collecting segmentation-models-pytorch\n",
      "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.24-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from segmentation-models-pytorch) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from segmentation-models-pytorch) (2.2.5)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from segmentation-models-pytorch) (11.2.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from segmentation-models-pytorch) (0.5.3)\n",
      "Requirement already satisfied: torch>=1.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from segmentation-models-pytorch) (2.9.1)\n",
      "Requirement already satisfied: torchvision>=0.9 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from segmentation-models-pytorch) (0.24.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from segmentation-models-pytorch) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/akhilgattu/Library/Python/3.13/lib/python/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8->segmentation-models-pytorch) (80.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8->segmentation-models-pytorch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.4.26)\n",
      "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
      "Downloading timm-1.0.24-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm, segmentation-models-pytorch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [segmentation-models-pytorch]\n",
      "\u001b[1A\u001b[2KSuccessfully installed segmentation-models-pytorch-0.5.0 timm-1.0.24\n",
      "Requirement already satisfied: albumentations in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.0.8)\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from albumentations) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from albumentations) (1.15.2)\n",
      "Requirement already satisfied: PyYAML in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from albumentations) (2.12.5)\n",
      "Requirement already satisfied: albucore==0.0.24 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from albumentations) (4.10.0.84)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from albucore==0.0.24->albumentations) (4.6.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from albucore==0.0.24->albumentations) (6.5.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.2.5)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.4.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.10.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (52 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/akhilgattu/Library/Python/3.13/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/akhilgattu/Library/Python/3.13/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/akhilgattu/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading numpy-2.4.1-cp313-cp313-macosx_14_0_arm64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.8-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, matplotlib\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.2.5\n",
      "\u001b[2K    Uninstalling numpy-2.2.5:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.5\n",
      "\u001b[2K  Attempting uninstall: matplotlib━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.1[32m0/2\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.1:━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [matplotlib]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [matplotlib]2\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
      "streamlit 1.22.0 requires protobuf<4,>=3.12, but you have protobuf 6.32.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed matplotlib-3.10.8 numpy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torch torchvision\n",
    "!pip install -U segmentation-models-pytorch timm\n",
    "!pip install -U albumentations opencv-python\n",
    "!pip install -U numpy tqdm matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250fa35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f3144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 54 | Train: 44 | Val: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing TRAIN: 100%|██████████| 44/44 [00:03<00:00, 11.83it/s]\n",
      "Preparing VAL: 100%|██████████| 10/10 [00:00<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sanity check -> data_idrid_multiclass/train/masks (showing 10)\n",
      "IDRiD_01.png | unique: [0 1 2 3 5] | nonzero_pixels: 369508\n",
      "IDRiD_02.png | unique: [0 1 2 3 5] | nonzero_pixels: 365750\n",
      "IDRiD_03.png | unique: [0 1 2 3 4 5] | nonzero_pixels: 717840\n",
      "IDRiD_04.png | unique: [0 1 2 3 5] | nonzero_pixels: 249335\n",
      "IDRiD_05.png | unique: [0 1 2 3 5] | nonzero_pixels: 238343\n",
      "IDRiD_07.png | unique: [0 1 2 3 5] | nonzero_pixels: 417478\n",
      "IDRiD_09.png | unique: [0 1 2 3 5] | nonzero_pixels: 633525\n",
      "IDRiD_10.png | unique: [0 1 2 3 5] | nonzero_pixels: 1146350\n",
      "IDRiD_11.png | unique: [0 1 2 3 5] | nonzero_pixels: 572246\n",
      "IDRiD_12.png | unique: [0 1 2 3 5] | nonzero_pixels: 374786\n",
      "\n",
      "Sanity check -> data_idrid_multiclass/val/masks (showing 10)\n",
      "IDRiD_06.png | unique: [0 1 2 3 5] | nonzero_pixels: 366131\n",
      "IDRiD_08.png | unique: [0 1 2 3 4 5] | nonzero_pixels: 305854\n",
      "IDRiD_18.png | unique: [0 1 2 3 4 5] | nonzero_pixels: 491177\n",
      "IDRiD_24.png | unique: [0 1 2 3 5] | nonzero_pixels: 247043\n",
      "IDRiD_28.png | unique: [0 1 2 3 5] | nonzero_pixels: 264526\n",
      "IDRiD_35.png | unique: [0 1 2 3 4 5] | nonzero_pixels: 633347\n",
      "IDRiD_38.png | unique: [0 1 2 3 4 5] | nonzero_pixels: 304455\n",
      "IDRiD_41.png | unique: [0 1 2 3 5] | nonzero_pixels: 227844\n",
      "IDRiD_52.png | unique: [0 1 2 3 4 5] | nonzero_pixels: 263430\n",
      "IDRiD_54.png | unique: [0 1 2 3 4 5] | nonzero_pixels: 300478\n",
      "\n",
      "Saving 8 debug previews in: debug_dataset_preview\n",
      "\n",
      "Saving 8 debug previews in: debug_dataset_preview\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/61/80bh8zbs3rg_9w2k2zqhghd00000gn/T/ipykernel_2068/649371302.py:302: UserWarning: Argument(s) 'value, mask_value' are not valid for transform ShiftScaleRotate\n",
      "  A.ShiftScaleRotate(\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | TrainLoss=0.5237 | ValLoss=0.4904 | ValDice(no-bg)=0.0372\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.0372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | TrainLoss=0.4818 | ValLoss=0.4696 | ValDice(no-bg)=0.0785\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.0785)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | TrainLoss=0.4612 | ValLoss=0.4514 | ValDice(no-bg)=0.1260\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.1260)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | TrainLoss=0.4463 | ValLoss=0.4352 | ValDice(no-bg)=0.1755\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.1755)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | TrainLoss=0.4318 | ValLoss=0.4282 | ValDice(no-bg)=0.1790\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.1790)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | TrainLoss=0.4234 | ValLoss=0.4200 | ValDice(no-bg)=0.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | TrainLoss=0.4117 | ValLoss=0.4090 | ValDice(no-bg)=0.1891\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.1891)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | TrainLoss=0.4019 | ValLoss=0.4051 | ValDice(no-bg)=0.2016\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.2016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | TrainLoss=0.3912 | ValLoss=0.3922 | ValDice(no-bg)=0.2143\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.2143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | TrainLoss=0.3838 | ValLoss=0.3852 | ValDice(no-bg)=0.2213\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.2213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | TrainLoss=0.3738 | ValLoss=0.3762 | ValDice(no-bg)=0.2766\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.2766)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | TrainLoss=0.3628 | ValLoss=0.3666 | ValDice(no-bg)=0.2948\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.2948)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | TrainLoss=0.3534 | ValLoss=0.3576 | ValDice(no-bg)=0.2976\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.2976)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | TrainLoss=0.3429 | ValLoss=0.3504 | ValDice(no-bg)=0.3280\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.3280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | TrainLoss=0.3329 | ValLoss=0.3445 | ValDice(no-bg)=0.3455\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.3455)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | TrainLoss=0.3199 | ValLoss=0.3316 | ValDice(no-bg)=0.3919\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.3919)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | TrainLoss=0.3092 | ValLoss=0.3206 | ValDice(no-bg)=0.4286\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.4286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | TrainLoss=0.2968 | ValLoss=0.3123 | ValDice(no-bg)=0.4319\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.4319)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | TrainLoss=0.2778 | ValLoss=0.3020 | ValDice(no-bg)=0.4556\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.4556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | TrainLoss=0.2681 | ValLoss=0.2939 | ValDice(no-bg)=0.4199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | TrainLoss=0.2623 | ValLoss=0.2786 | ValDice(no-bg)=0.4751\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.4751)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | TrainLoss=0.2540 | ValLoss=0.2729 | ValDice(no-bg)=0.4365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | TrainLoss=0.2496 | ValLoss=0.2812 | ValDice(no-bg)=0.4521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | TrainLoss=0.2569 | ValLoss=0.2735 | ValDice(no-bg)=0.4628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | TrainLoss=0.2528 | ValLoss=0.2785 | ValDice(no-bg)=0.4262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | TrainLoss=0.2355 | ValLoss=0.2640 | ValDice(no-bg)=0.4812\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.4812)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | TrainLoss=0.2275 | ValLoss=0.2570 | ValDice(no-bg)=0.4954\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.4954)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | TrainLoss=0.2258 | ValLoss=0.2626 | ValDice(no-bg)=0.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | TrainLoss=0.2369 | ValLoss=0.2626 | ValDice(no-bg)=0.4703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | TrainLoss=0.2171 | ValLoss=0.2518 | ValDice(no-bg)=0.5003\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.5003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | TrainLoss=0.2203 | ValLoss=0.2507 | ValDice(no-bg)=0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | TrainLoss=0.2143 | ValLoss=0.2487 | ValDice(no-bg)=0.5024\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.5024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | TrainLoss=0.2176 | ValLoss=0.2475 | ValDice(no-bg)=0.5077\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.5077)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | TrainLoss=0.2053 | ValLoss=0.2543 | ValDice(no-bg)=0.5050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | TrainLoss=0.2084 | ValLoss=0.2478 | ValDice(no-bg)=0.5104\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.5104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | TrainLoss=0.2009 | ValLoss=0.2565 | ValDice(no-bg)=0.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | TrainLoss=0.2093 | ValLoss=0.2528 | ValDice(no-bg)=0.5241\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.5241)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | TrainLoss=0.2081 | ValLoss=0.2436 | ValDice(no-bg)=0.5204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | TrainLoss=0.2165 | ValLoss=0.2363 | ValDice(no-bg)=0.5385\n",
      "Saved BEST -> checkpoints/unetpp_effb3_idrid_5class.pth (dice=0.5385)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | TrainLoss=0.2169 | ValLoss=0.2431 | ValDice(no-bg)=0.5137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) CONFIG\n",
    "# ============================================================\n",
    "BASE_DIR = \"/Users/akhilgattu/Desktop/VLM_project/\"  # change if needed\n",
    "SEG_DIR = os.path.join(BASE_DIR, \"A. Segmentation\")\n",
    "\n",
    "# Images (jpg)\n",
    "TRAIN_IMG_DIR = os.path.join(SEG_DIR, \"1. Original Images\", \"a. Training Set\")\n",
    "\n",
    "# GT root has lesion subfolders\n",
    "TRAIN_GT_ROOT = os.path.join(SEG_DIR, \"2. All Segmentation Groundtruths\", \"a. Training Set\")\n",
    "\n",
    "# Output dataset\n",
    "OUT_DIR = \"data_idrid_multiclass\"\n",
    "OUT_TRAIN_IMG = os.path.join(OUT_DIR, \"train\", \"images\")\n",
    "OUT_TRAIN_MSK = os.path.join(OUT_DIR, \"train\", \"masks\")\n",
    "OUT_VAL_IMG   = os.path.join(OUT_DIR, \"val\", \"images\")\n",
    "OUT_VAL_MSK   = os.path.join(OUT_DIR, \"val\", \"masks\")\n",
    "\n",
    "DEBUG_DIR = \"debug_dataset_preview\"\n",
    "CKPT_PATH = \"checkpoints/unetpp_effb3_idrid_5class.pth\"\n",
    "\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 40\n",
    "LR = 3e-4\n",
    "VAL_RATIO = 0.2\n",
    "SEED = 42\n",
    "\n",
    "NUM_CLASSES = 6  # 0..5 (0 is BG)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) IDRiD CLASS MAP + GT SUBFOLDERS\n",
    "# ============================================================\n",
    "# Your folder names (exactly as in your screenshot)\n",
    "GT_SUBFOLDERS = {\n",
    "    \"MA\": \"1. Microaneurysms\",\n",
    "    \"HE\": \"2. Haemorrhages\",\n",
    "    \"EX\": \"3. Hard Exudates\",\n",
    "    \"SE\": \"4. Soft Exudates\",\n",
    "    \"OD\": \"5. Optic Disc\",\n",
    "}\n",
    "\n",
    "CLASS_TO_ID = {\n",
    "    \"MA\": 1,\n",
    "    \"HE\": 2,\n",
    "    \"EX\": 3,\n",
    "    \"SE\": 4,\n",
    "    \"OD\": 5,\n",
    "}\n",
    "\n",
    "ID_TO_CLASS = {\n",
    "    0: \"BG\",\n",
    "    1: \"MA\",\n",
    "    2: \"HE\",\n",
    "    3: \"EX\",\n",
    "    4: \"SE\",\n",
    "    5: \"OD\",\n",
    "}\n",
    "\n",
    "# Colors for debug overlays (BGR)\n",
    "COLORS = {\n",
    "    0: (0, 0, 0),\n",
    "    1: (0, 0, 255),       # MA red\n",
    "    2: (0, 165, 255),     # HE orange\n",
    "    3: (0, 255, 255),     # EX yellow\n",
    "    4: (255, 0, 255),     # SE magenta\n",
    "    5: (255, 255, 0),     # OD cyan\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) UTILS\n",
    "# ============================================================\n",
    "def ensure_dirs():\n",
    "    os.makedirs(OUT_TRAIN_IMG, exist_ok=True)\n",
    "    os.makedirs(OUT_TRAIN_MSK, exist_ok=True)\n",
    "    os.makedirs(OUT_VAL_IMG, exist_ok=True)\n",
    "    os.makedirs(OUT_VAL_MSK, exist_ok=True)\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    os.makedirs(DEBUG_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def list_jpg_images(folder):\n",
    "    files = glob(os.path.join(folder, \"*.jpg\"))\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "\n",
    "def find_mask_path(gt_root, base_name, lesion_code):\n",
    "    \"\"\"\n",
    "    Given base_name like: IDRiD_01\n",
    "    Return path like:\n",
    "      TRAIN_GT_ROOT / \"1. Microaneurysms\" / \"IDRiD_01_MA.tif\"\n",
    "    \"\"\"\n",
    "    sub = GT_SUBFOLDERS[lesion_code]\n",
    "    folder = os.path.join(gt_root, sub)\n",
    "\n",
    "    # official naming is usually base_LESION.tif\n",
    "    p = os.path.join(folder, f\"{base_name}_{lesion_code}.tif\")\n",
    "    if os.path.exists(p):\n",
    "        return p\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_multiclass_mask(image_hw, gt_root, base_name):\n",
    "    \"\"\"\n",
    "    Merge all lesion binary masks into one multiclass mask (HxW).\n",
    "    Priority high overwrites low:\n",
    "      MA > HE > EX > SE > OD\n",
    "    \"\"\"\n",
    "    H, W = image_hw\n",
    "    mask = np.zeros((H, W), dtype=np.uint8)\n",
    "\n",
    "    # low->high so higher overwrites later\n",
    "    priority = [\"OD\", \"SE\", \"EX\", \"HE\", \"MA\"]\n",
    "\n",
    "    for lesion in priority:\n",
    "        mp = find_mask_path(gt_root, base_name, lesion)\n",
    "        if mp is None:\n",
    "            continue\n",
    "\n",
    "        m = cv2.imread(mp, cv2.IMREAD_GRAYSCALE)\n",
    "        if m is None:\n",
    "            continue\n",
    "\n",
    "        # IDRiD masks are usually 0 / 255\n",
    "        m_bin = (m > 0).astype(np.uint8)\n",
    "        cls_id = CLASS_TO_ID[lesion]\n",
    "        mask[m_bin == 1] = cls_id\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    h, w = mask.shape\n",
    "    out = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for cid, bgr in COLORS.items():\n",
    "        out[mask == cid] = bgr\n",
    "    return out\n",
    "\n",
    "\n",
    "def overlay(image_bgr, color_mask_bgr, alpha=0.45):\n",
    "    return cv2.addWeighted(image_bgr, 1 - alpha, color_mask_bgr, alpha, 0)\n",
    "\n",
    "\n",
    "def sanity_check_masks(masks_dir, n=20):\n",
    "    msks = glob(os.path.join(masks_dir, \"*.png\"))\n",
    "    msks.sort()\n",
    "    msks = msks[:n]\n",
    "\n",
    "    print(f\"\\nSanity check -> {masks_dir} (showing {len(msks)})\")\n",
    "    for mp in msks:\n",
    "        m = cv2.imread(mp, cv2.IMREAD_GRAYSCALE)\n",
    "        if m is None:\n",
    "            print(\"Cannot read:\", mp)\n",
    "            continue\n",
    "        uniq = np.unique(m)\n",
    "        nonzero = int((m > 0).sum())\n",
    "        print(os.path.basename(mp), \"| unique:\", uniq, \"| nonzero_pixels:\", nonzero)\n",
    "\n",
    "\n",
    "def debug_preview(images_dir, masks_dir, n=8):\n",
    "    imgs = list_jpg_images(images_dir)[:n]\n",
    "    print(f\"\\nSaving {len(imgs)} debug previews in: {DEBUG_DIR}\")\n",
    "\n",
    "    for ip in imgs:\n",
    "        base = os.path.splitext(os.path.basename(ip))[0]\n",
    "        mp = os.path.join(masks_dir, f\"{base}.png\")\n",
    "\n",
    "        img = cv2.imread(ip, cv2.IMREAD_COLOR)\n",
    "        msk = cv2.imread(mp, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None or msk is None:\n",
    "            continue\n",
    "\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        msk = cv2.resize(msk, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        col = colorize_mask(msk)\n",
    "        over = overlay(img, col, alpha=0.45)\n",
    "\n",
    "        cv2.imwrite(os.path.join(DEBUG_DIR, f\"{base}_gt_overlay.png\"), over)\n",
    "\n",
    "\n",
    "def prepare_train_val(force_rebuild=False):\n",
    "    \"\"\"\n",
    "    Create OUT_DIR train/val with masks merged into multiclass png.\n",
    "    \"\"\"\n",
    "    if not force_rebuild:\n",
    "        if len(os.listdir(OUT_TRAIN_MSK)) > 0 and len(os.listdir(OUT_VAL_MSK)) > 0:\n",
    "            print(\"Prepared dataset already exists. Skipping rebuild.\")\n",
    "            return\n",
    "\n",
    "    # optionally wipe old\n",
    "    if force_rebuild:\n",
    "        for p in [OUT_TRAIN_IMG, OUT_TRAIN_MSK, OUT_VAL_IMG, OUT_VAL_MSK]:\n",
    "            for f in glob(os.path.join(p, \"*\")):\n",
    "                os.remove(f)\n",
    "\n",
    "    img_paths = list_jpg_images(TRAIN_IMG_DIR)\n",
    "    if len(img_paths) == 0:\n",
    "        raise RuntimeError(f\"No .jpg images found in: {TRAIN_IMG_DIR}\")\n",
    "\n",
    "    # split\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    idx = np.arange(len(img_paths))\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    n_val = int(len(img_paths) * VAL_RATIO)\n",
    "    val_idx = idx[:n_val]\n",
    "    tr_idx = idx[n_val:]\n",
    "\n",
    "    train_paths = [img_paths[i] for i in tr_idx]\n",
    "    val_paths   = [img_paths[i] for i in val_idx]\n",
    "\n",
    "    print(f\"Total: {len(img_paths)} | Train: {len(train_paths)} | Val: {len(val_paths)}\")\n",
    "\n",
    "    def write_one(ip, out_img_dir, out_msk_dir):\n",
    "        img = cv2.imread(ip, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Cannot read image: {ip}\")\n",
    "\n",
    "        H, W = img.shape[:2]\n",
    "        base = os.path.splitext(os.path.basename(ip))[0]\n",
    "\n",
    "        msk = build_multiclass_mask((H, W), TRAIN_GT_ROOT, base)\n",
    "\n",
    "        cv2.imwrite(os.path.join(out_img_dir, os.path.basename(ip)), img)\n",
    "        cv2.imwrite(os.path.join(out_msk_dir, f\"{base}.png\"), msk)\n",
    "\n",
    "    for ip in tqdm(train_paths, desc=\"Preparing TRAIN\"):\n",
    "        write_one(ip, OUT_TRAIN_IMG, OUT_TRAIN_MSK)\n",
    "\n",
    "    for ip in tqdm(val_paths, desc=\"Preparing VAL\"):\n",
    "        write_one(ip, OUT_VAL_IMG, OUT_VAL_MSK)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) DATASET + AUGS\n",
    "# ============================================================\n",
    "class MultiClassSegDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images = list_jpg_images(images_dir)\n",
    "        self.masks = []\n",
    "        for ip in self.images:\n",
    "            base = os.path.splitext(os.path.basename(ip))[0]\n",
    "            self.masks.append(os.path.join(masks_dir, f\"{base}.png\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ip = self.images[idx]\n",
    "        mp = self.masks[idx]\n",
    "\n",
    "        img = cv2.imread(ip, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Cannot read image: {ip}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = cv2.imread(mp, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(f\"Missing mask: {mp}\")\n",
    "\n",
    "        if self.transform:\n",
    "            out = self.transform(image=img, mask=mask)\n",
    "            img = out[\"image\"]\n",
    "            mask = out[\"mask\"]\n",
    "\n",
    "        mask = torch.as_tensor(mask, dtype=torch.long)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "def get_train_tfms(sz=512):\n",
    "    return A.Compose([\n",
    "        A.Resize(sz, sz),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.CLAHE(p=0.3),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.3),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.05, scale_limit=0.10, rotate_limit=20,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=0, mask_value=0, p=0.5\n",
    "        ),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_val_tfms(sz=512):\n",
    "    return A.Compose([\n",
    "        A.Resize(sz, sz),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) LOSS\n",
    "# ============================================================\n",
    "class DiceLossMulticlass(nn.Module):\n",
    "    def __init__(self, num_classes, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        targets_1h = F.one_hot(targets, num_classes=self.num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        dims = (0, 2, 3)\n",
    "        intersection = torch.sum(probs * targets_1h, dims)\n",
    "        union = torch.sum(probs, dims) + torch.sum(targets_1h, dims)\n",
    "\n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1.0 - dice.mean()\n",
    "\n",
    "\n",
    "class FocalLossMulticlass(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # tensor [C]\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce = F.cross_entropy(logits, targets, weight=self.alpha, reduction=\"none\")\n",
    "        pt = torch.exp(-ce)\n",
    "        loss = ((1 - pt) ** self.gamma) * ce\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class DiceFocalLoss(nn.Module):\n",
    "    def __init__(self, num_classes, dice_w=0.5, focal_w=0.5, gamma=2.0, alpha=None):\n",
    "        super().__init__()\n",
    "        self.dice = DiceLossMulticlass(num_classes)\n",
    "        self.focal = FocalLossMulticlass(gamma=gamma, alpha=alpha)\n",
    "        self.dice_w = dice_w\n",
    "        self.focal_w = focal_w\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        return self.dice_w * self.dice(logits, targets) + self.focal_w * self.focal(logits, targets)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def mean_dice_no_bg(logits, targets, num_classes):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    dices = []\n",
    "    for c in range(1, num_classes):\n",
    "        p = (preds == c).float()\n",
    "        t = (targets == c).float()\n",
    "        inter = (p * t).sum()\n",
    "        denom = p.sum() + t.sum()\n",
    "        d = (2 * inter + 1.0) / (denom + 1.0)\n",
    "        dices.append(d)\n",
    "    return torch.stack(dices).mean().item()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) TRAIN\n",
    "# ============================================================\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def train():\n",
    "    device = get_device()\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    train_ds = MultiClassSegDataset(OUT_TRAIN_IMG, OUT_TRAIN_MSK, transform=get_train_tfms(IMG_SIZE))\n",
    "    val_ds   = MultiClassSegDataset(OUT_VAL_IMG,   OUT_VAL_MSK,   transform=get_val_tfms(IMG_SIZE))\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"timm-efficientnet-b3\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=NUM_CLASSES,\n",
    "        activation=None\n",
    "    ).to(device)\n",
    "\n",
    "    # Strong class weights (BG extremely downweighted)\n",
    "    alpha = torch.tensor([0.03, 2.5, 2.5, 2.5, 2.5, 1.8], dtype=torch.float32).to(device)\n",
    "\n",
    "    criterion = DiceFocalLoss(\n",
    "        num_classes=NUM_CLASSES,\n",
    "        dice_w=0.5,\n",
    "        focal_w=0.5,\n",
    "        gamma=2.0,\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\n",
    "    best_dice = -1e9\n",
    "\n",
    "    for ep in range(1, EPOCHS + 1):\n",
    "        # ---------------- TRAIN ----------------\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "\n",
    "        for imgs, masks in tqdm(train_loader, desc=f\"Train {ep}/{EPOCHS}\", leave=False):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "        tr_loss /= max(1, len(train_loader))\n",
    "\n",
    "        # ---------------- VAL ----------------\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        va_dice = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in tqdm(val_loader, desc=f\"Val {ep}/{EPOCHS}\", leave=False):\n",
    "                imgs = imgs.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                logits = model(imgs)\n",
    "                loss = criterion(logits, masks)\n",
    "\n",
    "                va_loss += loss.item()\n",
    "                va_dice += mean_dice_no_bg(logits, masks, NUM_CLASSES)\n",
    "\n",
    "        va_loss /= max(1, len(val_loader))\n",
    "        va_dice /= max(1, len(val_loader))\n",
    "\n",
    "        print(f\"Epoch {ep:02d} | TrainLoss={tr_loss:.4f} | ValLoss={va_loss:.4f} | ValDice(no-bg)={va_dice:.4f}\")\n",
    "\n",
    "        if va_dice > best_dice:\n",
    "            best_dice = va_dice\n",
    "            torch.save(model.state_dict(), CKPT_PATH)\n",
    "            print(f\"Saved BEST -> {CKPT_PATH} (dice={best_dice:.4f})\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    ensure_dirs()\n",
    "\n",
    "    # Prepare dataset (train/val from training set)\n",
    "    prepare_train_val(force_rebuild=True)\n",
    "\n",
    "    # Sanity check (should show non-zero pixels)\n",
    "    sanity_check_masks(OUT_TRAIN_MSK, n=10)\n",
    "    sanity_check_masks(OUT_VAL_MSK, n=10)\n",
    "\n",
    "    # Save GT overlay previews so you visually confirm masks are correct\n",
    "    debug_preview(OUT_TRAIN_IMG, OUT_TRAIN_MSK, n=8)\n",
    "    debug_preview(OUT_VAL_IMG, OUT_VAL_MSK, n=8)\n",
    "\n",
    "    print(\"\\nStarting training...\\n\")\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2c686ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhilgattu/Desktop/VLM_project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3efbc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Found 27 images.\n",
      "\n",
      "Saved results in: visual_results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# CONFIG\n",
    "# --------------------------\n",
    "CKPT_PATH = \"/Users/akhilgattu/Desktop/VLM_project/checkpoints/unetpp_effb3_idrid_5class.pth\"\n",
    "IMG_DIR   = \"/Users/akhilgattu/Desktop/VLM_project/A. Segmentation/1. Original Images/b. Testing Set\"\n",
    "\n",
    "OUT_DIR = \"visual_results\"\n",
    "IMG_SIZE = 512\n",
    "NUM_CLASSES = 6  # 0..5\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# CLASS COLORS (BGR)\n",
    "# --------------------------\n",
    "COLORS = {\n",
    "    0: (0, 0, 0),         # BG - black\n",
    "    1: (0, 0, 255),       # MA - red\n",
    "    2: (0, 165, 255),     # HE - orange\n",
    "    3: (0, 255, 255),     # EX - yellow\n",
    "    4: (255, 0, 255),     # SE - magenta\n",
    "    5: (255, 255, 0),     # OD - cyan\n",
    "}\n",
    "\n",
    "CLASS_NAMES = {\n",
    "    0: \"BG\",\n",
    "    1: \"MA\",\n",
    "    2: \"HE\",\n",
    "    3: \"EX\",\n",
    "    4: \"SE\",\n",
    "    5: \"OD\",\n",
    "}\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# TRANSFORM\n",
    "# --------------------------\n",
    "def get_tfms(img_size=512):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# UTILS\n",
    "# --------------------------\n",
    "def list_images(folder):\n",
    "    exts = (\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\")\n",
    "    files = [f for f in os.listdir(folder) if f.lower().endswith(exts)]\n",
    "    files.sort()\n",
    "    return [os.path.join(folder, f) for f in files]\n",
    "\n",
    "\n",
    "def colorize_mask(mask):\n",
    "    \"\"\"mask: HxW int (0..NUM_CLASSES-1)\"\"\"\n",
    "    h, w = mask.shape\n",
    "    color = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for k, bgr in COLORS.items():\n",
    "        color[mask == k] = bgr\n",
    "    return color\n",
    "\n",
    "\n",
    "def overlay(image_bgr, color_mask_bgr, alpha=0.45):\n",
    "    return cv2.addWeighted(image_bgr, 1 - alpha, color_mask_bgr, alpha, 0)\n",
    "\n",
    "\n",
    "def draw_boundaries(base_bgr, mask, thickness=2):\n",
    "    \"\"\"\n",
    "    Draw class boundaries so segmentation pops.\n",
    "    \"\"\"\n",
    "    out = base_bgr.copy()\n",
    "    for cls_id in range(1, NUM_CLASSES):  # skip BG\n",
    "        bin_mask = (mask == cls_id).astype(np.uint8) * 255\n",
    "        contours, _ = cv2.findContours(bin_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(out, contours, -1, (255, 255, 255), thickness)\n",
    "    return out\n",
    "\n",
    "\n",
    "def put_legend(img_bgr, mask, top_k=6):\n",
    "    \"\"\"\n",
    "    Add legend with class names + pixel %.\n",
    "    \"\"\"\n",
    "    out = img_bgr.copy()\n",
    "    h, w = out.shape[:2]\n",
    "\n",
    "    # compute class stats\n",
    "    total = h * w\n",
    "    counts = [(cid, int((mask == cid).sum())) for cid in range(NUM_CLASSES)]\n",
    "    counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    x0, y0 = 15, 25\n",
    "    line_h = 22\n",
    "\n",
    "    cv2.putText(out, \"Legend:\", (x0, y0),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    y = y0 + 25\n",
    "\n",
    "    # show top_k classes excluding BG if you want\n",
    "    shown = 0\n",
    "    for cid, c in counts:\n",
    "        if shown >= top_k:\n",
    "            break\n",
    "\n",
    "        pct = (c / total) * 100.0\n",
    "        name = CLASS_NAMES.get(cid, str(cid))\n",
    "        bgr = COLORS.get(cid, (255, 255, 255))\n",
    "\n",
    "        # color box\n",
    "        cv2.rectangle(out, (x0, y - 14), (x0 + 16, y + 2), bgr, -1)\n",
    "\n",
    "        # text\n",
    "        text = f\"{name}: {pct:.2f}%\"\n",
    "        cv2.putText(out, text, (x0 + 25, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        y += line_h\n",
    "        shown += 1\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def label_regions(img_bgr, mask):\n",
    "    \"\"\"\n",
    "    Put class labels at the center of each segmented blob.\n",
    "    \"\"\"\n",
    "    out = img_bgr.copy()\n",
    "\n",
    "    for cls_id in range(1, NUM_CLASSES):  # skip BG\n",
    "        bin_mask = (mask == cls_id).astype(np.uint8) * 255\n",
    "\n",
    "        # clean tiny noise\n",
    "        bin_mask = cv2.morphologyEx(bin_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "        contours, _ = cv2.findContours(bin_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area < 200:  # ignore tiny blobs\n",
    "                continue\n",
    "\n",
    "            M = cv2.moments(cnt)\n",
    "            if M[\"m00\"] == 0:\n",
    "                continue\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "            label = CLASS_NAMES.get(cls_id, str(cls_id))\n",
    "\n",
    "            # shadow text for visibility\n",
    "            cv2.putText(out, label, (cx, cy),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 4, cv2.LINE_AA)\n",
    "            cv2.putText(out, label, (cx, cy),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# MAIN\n",
    "# --------------------------\n",
    "def main():\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Correct device selection for Mac MPS\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"timm-efficientnet-b3\",\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        classes=NUM_CLASSES,\n",
    "        activation=None,\n",
    "    ).to(device)\n",
    "\n",
    "    ckpt = torch.load(CKPT_PATH, map_location=device)\n",
    "\n",
    "    # If checkpoint is {\"model\": state_dict} or {\"state_dict\": ...}\n",
    "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "        state_dict = ckpt[\"state_dict\"]\n",
    "    elif isinstance(ckpt, dict) and \"model\" in ckpt:\n",
    "        state_dict = ckpt[\"model\"]\n",
    "    else:\n",
    "        state_dict = ckpt\n",
    "\n",
    "    # remove \"module.\" if trained with DataParallel\n",
    "    new_state = {}\n",
    "    for k, v in state_dict.items():\n",
    "        nk = k.replace(\"module.\", \"\")\n",
    "        new_state[nk] = v\n",
    "\n",
    "    model.load_state_dict(new_state, strict=True)\n",
    "    model.eval()\n",
    "\n",
    "    tfms = get_tfms(IMG_SIZE)\n",
    "\n",
    "    img_paths = list_images(IMG_DIR)\n",
    "    if len(img_paths) == 0:\n",
    "        raise RuntimeError(f\"No images found in {IMG_DIR}\")\n",
    "\n",
    "    print(f\"Found {len(img_paths)} images.\")\n",
    "\n",
    "    for ip in img_paths:\n",
    "        fname = os.path.splitext(os.path.basename(ip))[0]\n",
    "\n",
    "        img_bgr = cv2.imread(ip, cv2.IMREAD_COLOR)\n",
    "        if img_bgr is None:\n",
    "            print(f\"Skipping (cannot read): {ip}\")\n",
    "            continue\n",
    "\n",
    "        img_bgr = cv2.resize(img_bgr, (IMG_SIZE, IMG_SIZE))\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        out = tfms(image=img_rgb)\n",
    "        x = out[\"image\"].unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)  # [1,C,H,W]\n",
    "            pred = torch.argmax(logits, dim=1)  # [1,H,W]\n",
    "            pred_mask = pred.squeeze(0).detach().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "        pred_color = colorize_mask(pred_mask)\n",
    "        pred_overlay = overlay(img_bgr, pred_color, alpha=0.45)\n",
    "\n",
    "        # make it visually strong\n",
    "        pred_overlay = draw_boundaries(pred_overlay, pred_mask, thickness=2)\n",
    "        pred_overlay = label_regions(pred_overlay, pred_mask)\n",
    "        pred_overlay = put_legend(pred_overlay, pred_mask)\n",
    "\n",
    "        # Save outputs\n",
    "        # Best format for raw mask is PNG (lossless)\n",
    "        cv2.imwrite(os.path.join(OUT_DIR, f\"{fname}_mask.png\"), pred_mask)\n",
    "\n",
    "        # Color mask\n",
    "        cv2.imwrite(os.path.join(OUT_DIR, f\"{fname}_color.png\"), pred_color)\n",
    "\n",
    "        # Overlay with labels\n",
    "        cv2.imwrite(os.path.join(OUT_DIR, f\"{fname}_overlay_labeled.png\"), pred_overlay)\n",
    "\n",
    "    print(f\"\\nSaved results in: {OUT_DIR}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
